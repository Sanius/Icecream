version: '2'
services:
  postgres:
    image: postgres:9.6
    container_name: postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_PASSWORD: postgres_password
      POSTGRES_USER: postgres_user
      POSTGRES_DB: postgres_db
  redis:
    image: redis
    container_name: redis
    ports:
      - "6379:6379"
  mysql:
    image: mysql:5.6
    container_name: mysql
    command: --default-authentication-plugin=mysql_native_password
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: rootpass
      MYSQL_DATABASE: datacollector
      MYSQL_USER: datacollector
      MYSQL_PASSWORD: datacollectorci
    ports:
      - "3306:3306"
  neo4j:
    build: ./neo4j
    container_name: neo4j
    depends_on:
      - zookeeper
      - kafka
      - schema-registry
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - "$HOME/neo4j/data:/data"
    environment:
      NEO4J_ACCEPT_LICENSE_AGREEMENT: 'yes'
      NEO4J_kafka_zookeeper_connect: 'zookeeper:2181'
      NEO4J_kafka_bootstrap_servers: 'kafka:29092'
      NEO4J_kafka_schema_registry_url: 'http://schema-registry:8081'
  zookeeper:
    image: confluentinc/cp-zookeeper:5.2.1
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
  kafka:
    image: confluentinc/cp-kafka:5.2.1
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "29092:29092"
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
  schema-registry:
    image: confluentinc/cp-schema-registry:5.2.1
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - zookeeper
      - kafka
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: 'zookeeper:2181'
  # control-center:
  #   image: confluentinc/cp-enterprise-control-center:5.2.1
  #   hostname: control-center
  #   container_name: control-center
  #   depends_on:
  #     - zookeeper
  #     - kafka
  #     - schema-registry
  #     - kafka-connect
  #     # - ksql-server
  #   ports:
  #     - "9021:9021"
  #   environment:
  #     CONTROL_CENTER_BOOTSTRAP_SERVERS: 'kafka:29092'
  #     CONTROL_CENTER_ZOOKEEPER_CONNECT: 'zookeeper:2181'
  #     CONTROL_CENTER_CONNECT_CLUSTER: 'kafka-connect:28083'
  #     # CONTROL_CENTER_KSQL_URL: "http://ksql-server:8088"
  #     # CONTROL_CENTER_KSQL_ADVERTISED_URL: "http://localhost:8088"
  #     CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
  #     CONTROL_CENTER_REPLICATION_FACTOR: 1
  #     CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
  #     CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
  #     CONFLUENT_METRICS_TOPIC_REPLICATION: 1
  #     PORT: 9021

  # kafka-connect:
  #   image: confluentinc/cp-kafka-connect:5.2.1
  #   hostname: kafka-connect
  #   container_name: kafka-connect
  #   depends_on:
  #     - zookeeper
  #     - kafka
  #     - schema-registry
  #     - postgres
  #   ports:
  #     - "28083:28083"
  #   volumes:
  #     - "/tmp/docker-kafkaconnect/file:/tmp/docker-kafkaconnect"
  #     - "/tmp/docker-kafkaconnect/jars:/etc/kafka-connect/jars"
  #   environment:
  #     CONNECT_BOOTSTRAP_SERVERS: 'kafka:29092'
  #     CONNECT_REST_PORT: 28083
  #     CONNECT_GROUP_ID: 'docker-kafkaconnect'
  #     CONNECT_CONFIG_STORAGE_TOPIC: 'docker-kafkaconnect-config'
  #     CONNECT_OFFSET_STORAGE_TOPIC: 'docker-kafkaconnect-offsets'
  #     CONNECT_STATUS_STORAGE_TOPIC: 'docker-kafkaconnect-status'
  #     CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
  #     CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
  #     CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
  #     CONNECT_KEY_CONVERTER: 'org.apache.kafka.connect.storage.StringConverter'
  #     CONNECT_VALUE_CONVERTER: 'io.confluent.connect.avro.AvroConverter'
  #     CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
  #     CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
  #     CONNECT_INTERNAL_KEY_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
  #     CONNECT_INTERNAL_VALUE_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
  #     CONNECT_REST_ADVERTISED_HOST_NAME: 'kafka-connect'
  #     CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
  #     CONNECT_PLUGIN_PATH: /usr/share/java,/etc/kafka-connect/jars
  # ksql-server:
  #   image: confluentinc/cp-ksql-server:5.2.1
  #   hostname: ksql-server
  #   container_name: ksql-server
  #   links:
  #     - kafka
  #   ports:
  #     - "8088:8088"
  #   environment:
  #     KSQL_CONFIG_DIR: "/etc/ksql"
  #     KSQL_LOG4J_OPTS: "-Dlog4j.configuration=file:/etc/ksql/log4j-rolling.properties"
  #     KSQL_BOOTSTRAP_SERVERS: "kafka:29092"
  #     KSQL_HOST_NAME: ksql-server
  #     KSQL_APPLICATION_ID: "cp-all-in-one"
  #     KSQL_LISTENERS: "http://0.0.0.0:8088"
  #     KSQL_CACHE_MAX_BYTES_BUFFERING: 0
  #     # KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
  #     KSQL_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
  #     KSQL_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
  # issue-scanner:
  #   build: ../../../issue-scanner
  #   container_name: issue-scanner
  #   command: java -Xmx400m -Xms400m  -jar issue-scanner.jar
  #   depends_on:
  #     - redis
  #     - kafka
  #   environment:
  #     SPRING_KAFKA_BOOTSTRAPSERVERS: 'kafka:29092'
  #     REDIS_SERVER: 'redis:6379'
  #   ports:
  #     - "8080:8080"
  # issue-scanner-jobtask:
  #   build: ../../../issue-scanner
  #   container_name: issue-scanner-jobtask
  #   command: java -cp issue-scanner.jar -Dloader.main=com.unified.platform.scanner.ScannerApp org.springframework.boot.loader.PropertiesLauncher kafka:29092 redis:6379
  #   depends_on:
  #     - kafka
  #     - redis
  #     - mysql
  #   environment:
  #     SPRING_KAFKA_BOOTSTRAPSERVERS: 'kafka:29092'
  #     REDIS_SERVER: 'redis:6379'
  # collection-engine-generator:
  #   build: ../../../Collection-Engine/
  #   command: java -cp collection-engine.jar com.unified.platform.collectionengine.RunTaskGenerator
  #   depends_on:
  #     - kafka
  #     - redis
  #     - mysql
  #   environment:
  #     MYSQL_DATABASE_CONNECTION: 'mysql:3306'
  #     KAFKA_BOOTSTRAP_SERVERS: 'kafka:29092'
  #     REDIS_SERVER: 'redis:6379'
  # collection-engine-consumer-generator:
  #   build: ../../../Collection-Engine/
  #   container_name: collection-engine-consumer-generator
  #   command: java -cp collection-engine.jar com.unified.platform.collectionengine.RunConsumingTaskGenerator
  #   depends_on:
  #     - kafka
  #     - redis
  #     - mysql
  #   environment:
  #     MYSQL_DATABASE_CONNECTION: 'mysql:3306'
  #     KAFKA_BOOTSTRAP_SERVERS: 'kafka:29092'
  #     REDIS_SERVER: 'redis:6379'
  # collection-engine-executor:
  #   build: ../../../Collection-Engine/
  #   container_name: collection-engine-executor
  #   command: java -DsplitEvents=true -cp collection-engine.jar com.unified.platform.collectionengine.RunTaskExecutor
  #   depends_on:
  #     - kafka
  #     - redis
  #     - mysql
  #   environment:
  #     MYSQL_DATABASE_CONNECTION: 'mysql:3306'
  #     KAFKA_BOOTSTRAP_SERVERS: 'kafka:29092'
  #     REDIS_SERVER: 'redis:6379'
  # collection-engine-deferer:
  #   build: ../../../Collection-Engine/
  #   container_name: collection-engine-deferer
  #   command: java -DsplitEvents=true -cp collection-engine.jar com.unified.platform.collectionengine.RunDeferredTaskMonitor
  #   depends_on:
  #     - kafka
  #     - redis
  #     - mysql
  #   environment:
  #     MYSQL_DATABASE_CONNECTION: 'mysql:3306'
  #     KAFKA_BOOTSTRAP_SERVERS: 'kafka:29092'
  #     REDIS_SERVER: 'redis:6379'
  pmn:
    build: ../../../pmn/
    container_name: pmn
    depends_on:
      - neo4j
    ports:
      - "28081:8081"
    environment:
      NEO4J_HOST: 'neo4j'
      NEO4J_PORT: '7474'
      NEO4J_PROTOCOL: 'http'
      HOST: '0.0.0.0'
      PORT: '8081'

  platform_api:
    build: ../../../platform/
    container_name: platform_api
    depends_on:
      - redis
      - pmn
      - communique
    ports:
      - "28080:8080"
    environment:
      HOST: '0.0.0.0'
      PORT: '8080'
      REDIS_HOST: 'redis'
      REDIS_PORT: '6379'
      REDIS_DB: '0'
      AUTH_BACKEND: 'bypass'
      PMN_HOST: 'pmn'
      PMN_PORT: '8081'
      DW_HOST: 'communique'
      DW_PORT: '8084'
      DW_PROTOCOL: 'http'

  communique:
    build: ../../../platform-communique/
    container_name: communique
    depends_on:
      - postgres
      - redis
      - pmn
    ports:
      - "28084:8084"
    environment: 
      ENV: 'dev'
      HOST: 'localhost'
      PORT: '8084'
      PC_DATA_CACHE: 'redis://redis:6379/0'
      PC_DATA_CACHE_ENABLED: 'True'
      PC_LOG_LEVEL: 'DEBUG'
      PC_ERROR_LOG_FILE: '/tmp/communique_error.log'
      PC_LOG_FILE: '/tmp/communique.log'
      PC_DW_CONNECTION_POOL_MAX: '10'
      DATA_WAREHOUSE: 'postgresql://user:password@localhost:5439/statsdb'
      RDS_REPORTING_DATABASE: 'postgresql://tin.nguyen:CG8MvRHZsgE2AUURnmhWg@host.docker.internal:5423/statsdb'
      PMN_API: 'http://pmn:8081'
      EM_API: 'http://neo4j:7474'
      OPTIMIZER_API: 'http://optimizer:8085'
      MAPBOX_API_TOKEN: 'pk.eyJ1Ijoiam9obi1hdC11bmlmaWVkIiwiYSI6ImNrN2NtdG9yNzAxOXczaHFoM2E2ZWo5Y2EifQ.W3pGVsDpDjxoL5aVKzhEMg'
